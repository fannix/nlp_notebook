{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": [],
      "mount_file_id": "1ha91y_TsIN6sCfYr3InkCZoIkQD43CUB",
      "authorship_tag": "ABX9TyMfldRCpaMPW9oQa/+Csv1B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fannix/nlp_notebook/blob/master/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dJRrZOzSP0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "feb63e74-a9c7-4cd4-dbd5-736dd9874243"
      },
      "source": [
        "!wget http://mattmahoney.net/dc/text8.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-15 19:39:34--  http://mattmahoney.net/dc/text8.zip\n",
            "Resolving mattmahoney.net (mattmahoney.net)... 67.195.197.75\n",
            "Connecting to mattmahoney.net (mattmahoney.net)|67.195.197.75|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31344016 (30M) [application/zip]\n",
            "Saving to: ‘text8.zip’\n",
            "\n",
            "text8.zip           100%[===================>]  29.89M   909KB/s    in 34s     \n",
            "\n",
            "2020-04-15 19:40:08 (897 KB/s) - ‘text8.zip’ saved [31344016/31344016]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF_j56NzSTrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bbc1cdeb-f516-48e9-8815-db858e3479bc"
      },
      "source": [
        "! unzip text8.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  text8.zip\n",
            "  inflating: text8                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zamDf_DGADn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def any2unicode(text, encoding='utf8', errors='strict'):\n",
        "  \"\"\"Convert `text` (bytestring in given encoding or unicode) to unicode.\n",
        "  \"\"\"\n",
        "  return str(text, encoding, errors=errors)\n",
        "\n",
        "MAX_WORDS_IN_BATCH = 10000\n",
        "\n",
        "import smart_open\n",
        "\n",
        "class Text8Corpus(object):\n",
        "  def __init__(self, fname, max_sentence_length=MAX_WORDS_IN_BATCH):\n",
        "    self.fname = fname\n",
        "    self.max_sentence_length = max_sentence_length\n",
        "\n",
        "  def __iter__(self):\n",
        "    # the entire corpus is one gigantic line -- there are no sentence marks at all\n",
        "    # so just split the sequence of toens arbitrarily: 1 sentence = 1000 tokens\n",
        "    sentence, rest = [], b''\n",
        "    with smart_open.smart_open(self.fname) as fin:\n",
        "      while True:\n",
        "        text = rest + fin.read(8192)\n",
        "        if text == rest:\n",
        "          words = any2unicode(text).split()\n",
        "          sentence.extend(words)\n",
        "          if sentence:\n",
        "            yield sentence\n",
        "          break\n",
        "        last_token = text.rfind(b' ')\n",
        "        words, rest = (any2unicode(text[:last_token]).split(),\n",
        "                       text[last_token:].strip()) if last_token >= 0 else ([], text)\n",
        "        sentence.extend(words)\n",
        "        while len(sentence) >= self.max_sentence_length:\n",
        "          yield sentence[:self.max_sentence_length]\n",
        "          sentence = sentence[self.max_sentence_length:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9FqMikARwfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1aefa315-e89b-43b2-d185-7eb0599536c5"
      },
      "source": [
        "corpus = Text8Corpus(\"text8\")\n",
        "from collections import Counter\n",
        "counter = Counter()\n",
        "for i, e in enumerate(corpus):\n",
        "  counter.update(e)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5BLnpLCS6ap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b0b2752f-e858-482f-c332-190aa6902c40"
      },
      "source": [
        "counter.most_common(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 1061396),\n",
              " ('of', 593677),\n",
              " ('and', 416629),\n",
              " ('one', 411764),\n",
              " ('in', 372201)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keyJkdL-TisU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 50000\n",
        "word2idx = {'UNK': 0}\n",
        "for word, _ in counter.most_common(VOCAB_SIZE-1):\n",
        "  word2idx[word] = len(word2idx)\n",
        "\n",
        "idx2word = dict(zip(word2idx.values(), word2idx.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQTjPGjaTLIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4YtKEERTR_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "96a26b56-9553-4aed-e4a3-e522e37f9b59"
      },
      "source": [
        "class Text8Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, max_sentence_length=MAX_WORDS_IN_BATCH):\n",
        "    super().__init__()\n",
        "    corpus = Text8Corpus(\"text8\", max_sentence_length)\n",
        "    self.x = []\n",
        "    self.y = []\n",
        "    for sentence in corpus:\n",
        "      for i in range(1, len(sentence) - 1):\n",
        "        left = word2idx.get(sentence[i - 1], 0)\n",
        "        word = word2idx.get(sentence[i], 0)\n",
        "        right = word2idx.get(sentence[i + 1], 0)\n",
        "        self.x.append(word)\n",
        "        self.y.append(left)\n",
        "        self.x.append(word)\n",
        "        self.y.append(right)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.x[i], self.y[i]\n",
        "\n",
        "dataset = Text8Dataset()\n",
        "data_loader = DataLoader(dataset, 128)\n",
        "\n",
        "for x, y in data_loader:\n",
        "  print(x, y)\n",
        "  break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([ 3081,  3081,    12,    12,     6,     6,   195,   195,     2,     2,\n",
            "         3134,  3134,    46,    46,    59,    59,   156,   156,   128,   128,\n",
            "          742,   742,   477,   477, 10572, 10572,   134,   134,     1,     1,\n",
            "        27350, 27350,     2,     2,     1,     1,   103,   103,   855,   855,\n",
            "            3,     3,     1,     1, 15068, 15068,     0,     0,     2,     2,\n",
            "            1,     1,   151,   151,   855,   855,  3581,  3581,     1,     1,\n",
            "          195,   195,    11,    11,   191,   191,    59,    59,     5,     5,\n",
            "            6,     6, 10713, 10713,   215,   215,     7,     7,  1325,  1325,\n",
            "          105,   105,   455,   455,    20,    20,    59,    59,  2732,  2732,\n",
            "          363,   363,     7,     7,  3673,  3673,     1,     1,   709,   709,\n",
            "            2,     2,   372,   372,    27,    27,    41,    41,    37,    37,\n",
            "           54,    54,   540,   540,    98,    98,    12,    12,     6,     6,\n",
            "         1424,  1424,  2758,  2758,    19,    19,   568,   568]) tensor([ 5234,    12,  3081,     6,    12,   195,     6,     2,   195,  3134,\n",
            "            2,    46,  3134,    59,    46,   156,    59,   128,   156,   742,\n",
            "          128,   477,   742, 10572,   477,   134, 10572,     1,   134, 27350,\n",
            "            1,     2, 27350,     1,     2,   103,     1,   855,   103,     3,\n",
            "          855,     1,     3, 15068,     1,     0, 15068,     2,     0,     1,\n",
            "            2,   151,     1,   855,   151,  3581,   855,     1,  3581,   195,\n",
            "            1,    11,   195,   191,    11,    59,   191,     5,    59,     6,\n",
            "            5, 10713,     6,   215, 10713,     7,   215,  1325,     7,   105,\n",
            "         1325,   455,   105,    20,   455,    59,    20,  2732,    59,   363,\n",
            "         2732,     7,   363,  3673,     7,     1,  3673,   709,     1,     2,\n",
            "          709,   372,     2,    27,   372,    41,    27,    37,    41,    54,\n",
            "           37,   540,    54,    98,   540,    12,    98,     6,    12,  1424,\n",
            "            6,  2758,  1424,    19,  2758,   568,    19,   687])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM14NEwrVXxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim\n",
        "cuda = torch.device('cuda')\n",
        "\n",
        "class SkipGram(nn.Module):\n",
        "  def __init__(self, num_word, num_dim):\n",
        "    super().__init__()\n",
        "    self.embedding_in = nn.Embedding(num_word, num_dim)\n",
        "    self.linear = nn.Linear(num_dim, num_word)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    em = self.embedding_in(X)\n",
        "    linear = self.linear(em)\n",
        "    return linear\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUocuNCMWKPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skip_gram = SkipGram(VOCAB_SIZE, 128).to(cuda)\n",
        "\n",
        "sgd = optim.Adam(skip_gram.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NemHOE1UW6fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(2):\n",
        "  running_loss = 0\n",
        "  for i, e in enumerate(data_loader):\n",
        "    input, target = e\n",
        "    input = input.to(cuda)\n",
        "    target = target.to(cuda)\n",
        "\n",
        "    sgd.zero_grad()\n",
        "    out = skip_gram(input)\n",
        "    batch_loss = criterion(out, target)\n",
        "    batch_loss.backward()\n",
        "    sgd.step()\n",
        "\n",
        "    running_loss += batch_loss.item()\n",
        "\n",
        "    if i % 100 == 99:\n",
        "      print('[%d, %5d] loss: %.3f' % (epoch, i, running_loss / 100))\n",
        "      running_loss = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syr0CHt4zXaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(skip_gram.state_dict(), \"skip_gram2.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85W7C5HszsIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "3a25c9c6-7bee-4753-fede-b5d4461d50e7"
      },
      "source": [
        "skip_gram.state_dict()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('embedding_in.weight',\n",
              "              tensor([[-0.1953,  0.1023,  0.5457,  ..., -0.3030,  0.2190,  0.2364],\n",
              "                      [-0.1474,  0.0351,  0.3400,  ..., -0.6073, -0.0495,  0.0216],\n",
              "                      [-0.6118,  1.0723,  0.0366,  ..., -0.2548,  0.0650,  0.0518],\n",
              "                      ...,\n",
              "                      [ 0.4745,  0.3977, -0.5545,  ..., -0.6421,  0.7280,  1.2740],\n",
              "                      [ 0.1979,  0.3360,  0.9031,  ..., -2.4365, -1.1855, -1.1454],\n",
              "                      [-0.2805, -0.9166,  0.1060,  ...,  0.4408, -0.6335, -1.7914]],\n",
              "                     device='cuda:0')),\n",
              "             ('linear.weight',\n",
              "              tensor([[ 4.0786, -6.3992, -4.4308,  ...,  5.4683, -4.6958, -5.5532],\n",
              "                      [ 4.1408, -6.3077, -4.5007,  ...,  5.4353, -4.6623, -5.4429],\n",
              "                      [ 4.1072, -6.5657, -4.3885,  ...,  5.4375, -4.6753, -5.7935],\n",
              "                      ...,\n",
              "                      [ 4.2185, -6.2939, -4.7321,  ...,  5.0268, -4.7996, -5.2787],\n",
              "                      [ 4.1539, -6.2671, -4.2556,  ...,  5.6136, -4.5212, -5.2813],\n",
              "                      [ 4.0148, -6.4245, -4.2045,  ...,  5.1557, -4.5455, -5.2989]],\n",
              "                     device='cuda:0')),\n",
              "             ('linear.bias',\n",
              "              tensor([ -6.4972,  -5.9426,  -6.9316,  ..., -32.1119, -31.7913, -33.1685],\n",
              "                     device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFCy5eUgz92r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_s07rmpYTra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "5da02539-e4e5-4004-c4cd-7744eec1265a"
      },
      "source": [
        "weight = skip_gram.state_dict()['embedding_in.weight'].cpu()\n",
        "# word_in = word2idx['one']\n",
        "word_in = word2idx['ball']\n",
        "li = []\n",
        "\n",
        "for i in range(VOCAB_SIZE):\n",
        "  if i != word_in:\n",
        "    similarity = cosine_similarity(\n",
        "        weight[word_in].reshape(1, -1),\n",
        "        weight[i].reshape(1, -1))\n",
        "    li.append((similarity, idx2word[i]))\n",
        "li.sort(reverse=True)\n",
        "li[:20]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([[0.47643974]], dtype=float32), 'team'),\n",
              " (array([[0.43092996]], dtype=float32), 'football'),\n",
              " (array([[0.41306]], dtype=float32), 'player'),\n",
              " (array([[0.41072005]], dtype=float32), 'flower'),\n",
              " (array([[0.4083807]], dtype=float32), 'bar'),\n",
              " (array([[0.39572728]], dtype=float32), 'line'),\n",
              " (array([[0.38700283]], dtype=float32), 'champion'),\n",
              " (array([[0.38408875]], dtype=float32), 'triple'),\n",
              " (array([[0.37671763]], dtype=float32), 'smooth'),\n",
              " (array([[0.37598515]], dtype=float32), 'jump'),\n",
              " (array([[0.3727573]], dtype=float32), 'label'),\n",
              " (array([[0.37117153]], dtype=float32), 'town'),\n",
              " (array([[0.3709255]], dtype=float32), 'push'),\n",
              " (array([[0.36844778]], dtype=float32), 'disc'),\n",
              " (array([[0.36836493]], dtype=float32), 'rod'),\n",
              " (array([[0.3680771]], dtype=float32), 'sky'),\n",
              " (array([[0.36607373]], dtype=float32), 'yellow'),\n",
              " (array([[0.365142]], dtype=float32), 'visitor'),\n",
              " (array([[0.3649454]], dtype=float32), 'round'),\n",
              " (array([[0.36466426]], dtype=float32), 'green')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}